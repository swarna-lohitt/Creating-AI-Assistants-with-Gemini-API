{
  "cells": [
    {
      "source": [
        "#Building AI Agent Assistant with OpenAI GPT-4o"
      ],
      "metadata": {
        "id": "d239c107-6848-4445-8166-e759bf7f8736"
      },
      "id": "d239c107-6848-4445-8166-e759bf7f8736",
      "cell_type": "markdown"
    },
    {
      "source": [
        "Create a GPT-4o file search assistant that summarizes and explains arxiv papers about AGI.\n",
        "\n",
        "The flow of this session is largely taken from the [OpenAI Assistants API documentation](https://platform.openai.com/docs/assistants/overview)."
      ],
      "metadata": {
        "id": "27405eab-76ef-4d8e-8b28-5f3322983267"
      },
      "id": "27405eab-76ef-4d8e-8b28-5f3322983267",
      "cell_type": "markdown"
    },
    {
      "source": [
        "#### Notes\n",
        "\n",
        "- OpenAI considers this much of this code experimental, so expect some changes in the coming months."
      ],
      "metadata": {
        "id": "4c85cd05-9145-4084-90e2-8c8ccddebffd"
      },
      "id": "4c85cd05-9145-4084-90e2-8c8ccddebffd",
      "cell_type": "markdown"
    },
    {
      "source": [
        "## Before you begin"
      ],
      "metadata": {
        "id": "8f62cfca-cf71-4321-bf20-00821a794ab1"
      },
      "id": "8f62cfca-cf71-4321-bf20-00821a794ab1",
      "cell_type": "markdown"
    },
    {
      "source": [
        "- Make sure you have an OpenAI developer account.\n",
        "- Your OpenAI developer account has credit on it.\n",
        "- Define an environment variable named `OPENAI_API_KEY` containing the API key."
      ],
      "metadata": {
        "id": "6109159e-4ba7-4d17-abaf-ba8104ae75bd"
      },
      "id": "6109159e-4ba7-4d17-abaf-ba8104ae75bd",
      "cell_type": "markdown"
    },
    {
      "source": [
        "## Task 0: Setup"
      ],
      "metadata": {
        "id": "06958f03-f502-43cb-b0af-139f05b00ef7"
      },
      "id": "06958f03-f502-43cb-b0af-139f05b00ef7",
      "cell_type": "markdown"
    },
    {
      "source": [
        "First we need to make sure that we are using the latest version of the OpenAI API package."
      ],
      "metadata": {
        "id": "3373f8ac-ba32-4463-b6a5-66f008d8406d"
      },
      "id": "3373f8ac-ba32-4463-b6a5-66f008d8406d",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Run this to install the latest version of the OpenAI package\n",
        "!pip install openai==1.33.0"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 7344,
        "lastExecutedAt": 1718113582649,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Run this to install the latest version of the OpenAI package\n!pip install openai==1.33.0",
        "outputsMetadata": {
          "0": {
            "height": 521,
            "type": "stream"
          }
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e54fd213-2621-42ae-94ae-bfd0f3402230",
        "outputId": "fdb7c575-d939-4d5c-b7d8-f17c418023cd"
      },
      "id": "e54fd213-2621-42ae-94ae-bfd0f3402230",
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.33.0\n",
            "  Downloading openai-1.33.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.33.0) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.33.0) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.33.0) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.33.0) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.33.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.33.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.33.0) (2.23.4)\n",
            "Downloading openai-1.33.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.52.2\n",
            "    Uninstalling openai-1.52.2:\n",
            "      Successfully uninstalled openai-1.52.2\n",
            "Successfully installed openai-1.33.0\n"
          ]
        }
      ]
    },
    {
      "source": [
        "We need the `os`, `openai`, and `pandas` packages."
      ],
      "metadata": {
        "id": "acaa9eb2-3622-47a8-98b9-17c8a6ba5af3"
      },
      "id": "acaa9eb2-3622-47a8-98b9-17c8a6ba5af3",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Import the `os` and `openai` packages without an alias.\n",
        "- Import the `pandas` package with its usual alias."
      ],
      "metadata": {
        "id": "4f518ced-a5ef-4cdb-bcf8-01c08868ca35"
      },
      "id": "4f518ced-a5ef-4cdb-bcf8-01c08868ca35",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Import the os package\n",
        "import os\n",
        "\n",
        "# Import the openai package\n",
        "import openai\n",
        "\n",
        "# Import the pandas package with an alias\n",
        "import pandas as pd"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 2055,
        "lastExecutedAt": 1718113584706,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Import the os package\nimport os\n\n# Import the openai package\nimport openai\n\n# Import the pandas package with an alias\nimport pandas as pd",
        "id": "c4800650-5f9d-4cc8-a3a4-f5a81e53ef44"
      },
      "id": "c4800650-5f9d-4cc8-a3a4-f5a81e53ef44",
      "cell_type": "code",
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "We need to define an OpenAI client."
      ],
      "metadata": {
        "id": "a9e61cbc-6367-4a2d-9bcc-ef4a64e6de25"
      },
      "id": "a9e61cbc-6367-4a2d-9bcc-ef4a64e6de25",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Define an OpenAI client. Assign to `client`."
      ],
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "id": "df61d8ab-7fb3-403e-b071-228b8b9644b5"
      },
      "id": "df61d8ab-7fb3-403e-b071-228b8b9644b5",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Define an OpenAI client. Assign to client.\n",
        "client = openai.OpenAI()"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 53,
        "lastExecutedAt": 1718113584761,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Define an OpenAI client. Assign to client.\nclient = openai.OpenAI()",
        "id": "2bdb5463-7586-4fec-bb70-d3527524d779"
      },
      "id": "2bdb5463-7586-4fec-bb70-d3527524d779",
      "cell_type": "code",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Task 1: Upload the Papers"
      ],
      "metadata": {
        "id": "712c314c-24d4-4af8-b678-7697dac54ae3"
      },
      "id": "712c314c-24d4-4af8-b678-7697dac54ae3",
      "cell_type": "markdown"
    },
    {
      "source": [
        "So that GPT knows about the latest AGI research, we will provide it with some arxiv papers. There are 10 recent papers on AGI stored in the `papers` directory of this workbook.\n",
        "\n",
        "_Click File -> Show workbook files to see a file browser._\n",
        "\n",
        "_The papers were found by searching arxiv for \"AGI\", then eyballing recent papers for content on definitions of AGI or progress towards AGI._\n",
        "\n",
        "The table below shows the filenames and the titles of the papers."
      ],
      "metadata": {
        "id": "b4295745-4a70-4496-8d84-3472f9519fda"
      },
      "id": "b4295745-4a70-4496-8d84-3472f9519fda",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Run this\n",
        "papers = pd.DataFrame({\n",
        "    \"filename\": [\n",
        "        \"2405.10313v1.pdf\",\n",
        "        \"2401.03428v1.pdf\",\n",
        "        \"2401.09395v2.pdf\",\n",
        "        \"2401.13142v3.pdf\",\n",
        "        \"2403.02164v2.pdf\",\n",
        "        \"2403.12107v1.pdf\",\n",
        "        \"2404.10731v1.pdf\",\n",
        "        \"2312.11562v5.pdf\",\n",
        "        \"2311.02462v2.pdf\",\n",
        "        \"2310.15274v1.pdf\"\n",
        "    ],\n",
        "    \"title\": [\n",
        "        \"How Far Are We From AGI?\",\n",
        "        \"EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS\",\n",
        "        \"CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions\",\n",
        "        \"Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse\",\n",
        "        \"Cognition is All You Need The Next Layer of AI Above Large Language Models\",\n",
        "        \"Scenarios for the Transition to AGI\",\n",
        "        \"What is Meant by AGI? On the Definition of Artificial General Intelligence\",\n",
        "        \"A Survey of Reasoning with Foundation Models\",\n",
        "        \"Levels of AGI: Operationalizing Progress on the Path to AGI\",\n",
        "        \"Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges\"\n",
        "    ]\n",
        "})\n",
        "papers[\"filename\"] = \"papers/\" + papers[\"filename\"]\n",
        "papers"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 53,
        "lastExecutedAt": 1718113584815,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Run this\npapers = pd.DataFrame({\n    \"filename\": [\n        \"2405.10313v1.pdf\",\n        \"2401.03428v1.pdf\",\n        \"2401.09395v2.pdf\",\n        \"2401.13142v3.pdf\",\n        \"2403.02164v2.pdf\",\n        \"2403.12107v1.pdf\",\n        \"2404.10731v1.pdf\",\n        \"2312.11562v5.pdf\",\n        \"2311.02462v2.pdf\",\n        \"2310.15274v1.pdf\"\n    ],\n    \"title\": [\n        \"How Far Are We From AGI?\",\n        \"EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS\",\n        \"CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions\",\n        \"Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse\",\n        \"Cognition is All You Need The Next Layer of AI Above Large Language Models\",\n        \"Scenarios for the Transition to AGI\",\n        \"What is Meant by AGI? On the Definition of Artificial General Intelligence\",\n        \"A Survey of Reasoning with Foundation Models\",\n        \"Levels of AGI: Operationalizing Progress on the Path to AGI\",\n        \"Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges\"\n    ]\n})\npapers[\"filename\"] = \"papers/\" + papers[\"filename\"]\npapers",
        "outputsMetadata": {
          "0": {
            "height": 361,
            "type": "dataFrame"
          }
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": true
        },
        "id": "5591f007-4b68-4b2a-ab00-4289b2b498cf",
        "outputId": "8cb6af72-f4f4-45c2-f3e4-879154b1e941"
      },
      "id": "5591f007-4b68-4b2a-ab00-4289b2b498cf",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/com.datacamp.data-table.v2+json": {
              "table": {
                "schema": {
                  "fields": [
                    {
                      "name": "index",
                      "type": "integer"
                    },
                    {
                      "name": "filename",
                      "type": "string"
                    },
                    {
                      "name": "title",
                      "type": "string"
                    }
                  ],
                  "primaryKey": [
                    "index"
                  ],
                  "pandas_version": "1.4.0"
                },
                "data": {
                  "index": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9
                  ],
                  "filename": [
                    "papers/2405.10313v1.pdf",
                    "papers/2401.03428v1.pdf",
                    "papers/2401.09395v2.pdf",
                    "papers/2401.13142v3.pdf",
                    "papers/2403.02164v2.pdf",
                    "papers/2403.12107v1.pdf",
                    "papers/2404.10731v1.pdf",
                    "papers/2312.11562v5.pdf",
                    "papers/2311.02462v2.pdf",
                    "papers/2310.15274v1.pdf"
                  ],
                  "title": [
                    "How Far Are We From AGI?",
                    "EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS",
                    "CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions",
                    "Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse",
                    "Cognition is All You Need The Next Layer of AI Above Large Language Models",
                    "Scenarios for the Transition to AGI",
                    "What is Meant by AGI? On the Definition of Artificial General Intelligence",
                    "A Survey of Reasoning with Foundation Models",
                    "Levels of AGI: Operationalizing Progress on the Path to AGI",
                    "Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges"
                  ]
                }
              },
              "total_rows": 10,
              "truncation_type": null
            },
            "text/plain": "                  filename                                              title\n0  papers/2405.10313v1.pdf                           How Far Are We From AGI?\n1  papers/2401.03428v1.pdf  EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGE...\n2  papers/2401.09395v2.pdf  CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM...\n3  papers/2401.13142v3.pdf  Unsocial Intelligence: an Investigation of the...\n4  papers/2403.02164v2.pdf  Cognition is All You Need The Next Layer of AI...\n5  papers/2403.12107v1.pdf                Scenarios for the Transition to AGI\n6  papers/2404.10731v1.pdf  What is Meant by AGI? On the Definition of Art...\n7  papers/2312.11562v5.pdf       A Survey of Reasoning with Foundation Models\n8  papers/2311.02462v2.pdf  Levels of AGI: Operationalizing Progress on th...\n9  papers/2310.15274v1.pdf  Systematic AI Approach for AGI: Addressing Ali...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>papers/2405.10313v1.pdf</td>\n      <td>How Far Are We From AGI?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>papers/2401.03428v1.pdf</td>\n      <td>EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGE...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>papers/2401.09395v2.pdf</td>\n      <td>CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>papers/2401.13142v3.pdf</td>\n      <td>Unsocial Intelligence: an Investigation of the...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>papers/2403.02164v2.pdf</td>\n      <td>Cognition is All You Need The Next Layer of AI...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>papers/2403.12107v1.pdf</td>\n      <td>Scenarios for the Transition to AGI</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>papers/2404.10731v1.pdf</td>\n      <td>What is Meant by AGI? On the Definition of Art...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>papers/2312.11562v5.pdf</td>\n      <td>A Survey of Reasoning with Foundation Models</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>papers/2311.02462v2.pdf</td>\n      <td>Levels of AGI: Operationalizing Progress on th...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>papers/2310.15274v1.pdf</td>\n      <td>Systematic AI Approach for AGI: Addressing Ali...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "source": [
        "To upload a file, you use `open()` to open it to get a file handle, then pass that handle to the client's `.files.create()` method. This returns details of the uploaded file, and the part we need to reuse is the file ID.\n"
      ],
      "metadata": {
        "id": "4997a841-fe9f-484e-abe7-c66e26debf67"
      },
      "id": "4997a841-fe9f-484e-abe7-c66e26debf67",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Run this code to define a function to upload a file to the assistant."
      ],
      "metadata": {
        "id": "8faba94a-14d8-4b40-b561-84b999206d8b"
      },
      "id": "8faba94a-14d8-4b40-b561-84b999206d8b",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Run this\n",
        "def upload_file_for_assistant(file_path):\n",
        "    uploaded_file = client.files.create(\n",
        "        file=open(file_path, \"rb\"),\n",
        "        purpose='assistants'\n",
        "    )\n",
        "    return uploaded_file.id"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 47,
        "lastExecutedAt": 1718113584862,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Run this\ndef upload_file_for_assistant(file_path): \n    uploaded_file = client.files.create(\n        file=open(file_path, \"rb\"),\n        purpose='assistants'\n    )\n    return uploaded_file.id",
        "id": "98bcae6e-3f54-4d0a-90ee-b33c1fd0894e"
      },
      "id": "98bcae6e-3f54-4d0a-90ee-b33c1fd0894e",
      "cell_type": "code",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Now we apply the `upload_file_for_assistant()` function to each filename in the papers dataset to upload them."
      ],
      "metadata": {
        "id": "8eb0dfed-71b6-4262-88a9-2a60cf33e5ae"
      },
      "id": "8eb0dfed-71b6-4262-88a9-2a60cf33e5ae",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- In `papers`, select the `filename` column, then apply `upload_file_for_assistant()`, then convert the result to a list. Assign to `uploaded_file_ids`."
      ],
      "metadata": {
        "id": "3e711b2a-4893-4343-b5b3-1129cb8980a6"
      },
      "id": "3e711b2a-4893-4343-b5b3-1129cb8980a6",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# In papers, select the filename column,\n",
        "# then apply upload_file_for_assistant(),\n",
        "# then convert the result to a list.\n",
        "# Assign to uploaded_file_ids.\n",
        "uploaded_file_ids = papers[\"filename\"] \\\n",
        "    .apply(upload_file_for_assistant) \\\n",
        "    .to_list()\n",
        "\n",
        "# See the result\n",
        "uploaded_file_ids"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 11878,
        "lastExecutedAt": 1718113596740,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# In papers, select the filename column, \n# then apply upload_file_for_assistant(),\n# then convert the result to a list. \n# Assign to uploaded_file_ids.\nuploaded_file_ids = papers[\"filename\"] \\\n    .apply(upload_file_for_assistant) \\\n    .to_list()\n\n# See the result\nuploaded_file_ids",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "id": "9d23ffbc-e8dc-4d84-8255-08b55da66270",
        "outputId": "a8385225-40d1-468c-a5df-afc958166758"
      },
      "id": "9d23ffbc-e8dc-4d84-8255-08b55da66270",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['file-MJNrdzgWXsq5dkWRlwMFvl6X',\n 'file-7Y3OWhfjFcT32CwjDEMYuSeg',\n 'file-FWredybeCfIpGrbdLslnvcK8',\n 'file-8AK41XPU9a7OKL9honKfLjwK',\n 'file-dTxCJwyiiS1oQGoFKo5ksdtu',\n 'file-yDPh4b3vMab9hu5FSXa3MsZQ',\n 'file-zwhNIl8U3kX62o80ed539o5z',\n 'file-TNwKe5iIVYlu6crDIMbKRZdj',\n 'file-S66Y4sD0AGN0dl1K3pj81kDZ',\n 'file-HZhROXHBtMSwbzofE1JY7nRQ']"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "source": [
        "### Check that this worked\n",
        "\n",
        "View the files in your account at https://platform.openai.com/storage/files"
      ],
      "metadata": {
        "id": "3d5dcf62-5677-4a95-bf43-48ab0ee7fdc9"
      },
      "id": "3d5dcf62-5677-4a95-bf43-48ab0ee7fdc9",
      "cell_type": "markdown"
    },
    {
      "source": [
        "## Task 2: Add the Files to a Vector Store"
      ],
      "metadata": {
        "id": "7c3e7127-c030-46ed-8226-9662af92198e"
      },
      "id": "7c3e7127-c030-46ed-8226-9662af92198e",
      "cell_type": "markdown"
    },
    {
      "source": [
        "To access the documents and get sensible results, they need to be split up into small chunks and added to a vector database.\n",
        "\n",
        "The assistants API lets you avoid worrying about the chunking stage, so you just need to specify the file IDs that you want to add to a vector database."
      ],
      "metadata": {
        "id": "97737898-14ef-4e20-8b9e-b77d63c0e941"
      },
      "id": "97737898-14ef-4e20-8b9e-b77d63c0e941",
      "cell_type": "markdown"
    },
    {
      "source": [
        "#### Notes\n",
        "\n",
        "- You will get charged daily for having a vector database. By default, it will automatically be deleted after 7 days of not being used, but I suggest deleting it straight after this code-along if you don't want to be charged for a week."
      ],
      "metadata": {
        "id": "46f37c72-dfd8-459f-a190-7a5d4d03765a"
      },
      "id": "46f37c72-dfd8-459f-a190-7a5d4d03765a",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Create a vector store, associating the uploaded file IDs and naming it. (Suggested name: `arxiv_agi_papers`.) Assign to `vstore`."
      ],
      "metadata": {
        "id": "2a891dae-6bc3-4667-a561-62acffa26d71"
      },
      "id": "2a891dae-6bc3-4667-a561-62acffa26d71",
      "cell_type": "markdown"
    },
    {
      "source": [
        "<details>\n",
        "  <summary>Code hints</summary>\n",
        "  <p>\n",
        "\n",
        "The code pattern for giving a vector store resource to a file search tool is as follows.\n",
        "        \n",
        "```py\n",
        "vstore = client.beta.vector_stores.create(\n",
        "    file_ids = file_ids,\n",
        "    name = \"vector store name\"\n",
        ")\n",
        "```\n",
        "        \n",
        "  </p>\n",
        "</details>   "
      ],
      "metadata": {
        "id": "6e232f63-c590-447c-b7f7-40563dc455bc"
      },
      "id": "6e232f63-c590-447c-b7f7-40563dc455bc",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Create a vector store, associating the uploaded file IDs and naming it.\n",
        "vstore = client.beta.vector_stores.create(\n",
        "    file_ids = uploaded_file_ids,\n",
        "    name = \"arxiv_agi_papers\"\n",
        ")\n",
        "\n",
        "# See the result\n",
        "vstore"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 844,
        "lastExecutedAt": 1718113597584,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Create a vector store, associating the uploaded file IDs and naming it.\nvstore = client.beta.vector_stores.create(\n    file_ids = uploaded_file_ids,\n    name = \"arxiv_agi_papers\"\n)\n\n# See the results\nvstore",
        "id": "4831a606-50c3-42be-9448-4ba44f49959a",
        "outputId": "6888ef68-d5aa-457d-dafb-a8affff1d5c8"
      },
      "id": "4831a606-50c3-42be-9448-4ba44f49959a",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "VectorStore(id='vs_L0SSKEAAJzOMnnQN8hssgHwR', created_at=1718113596, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=10, total=10), last_active_at=1718113596, metadata={}, name='arxiv_agi_papers', object='vector_store', status='in_progress', usage_bytes=0, expires_after=None, expires_at=None)"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "source": [
        "### Check that this worked\n",
        "\n",
        "View the vector stores in your account at https://platform.openai.com/storage/vector_stores"
      ],
      "metadata": {
        "id": "e7820b86-5729-423d-87e3-7fb8fff0bcb9"
      },
      "id": "e7820b86-5729-423d-87e3-7fb8fff0bcb9",
      "cell_type": "markdown"
    },
    {
      "source": [
        "## Task 3: Create the Assistant"
      ],
      "metadata": {
        "id": "8ed36d72-f053-408b-bcbb-76b679d158a7"
      },
      "id": "8ed36d72-f053-408b-bcbb-76b679d158a7",
      "cell_type": "markdown"
    },
    {
      "source": [
        "The assistant needs a prompt describing how it should behave. This consists of a few paragraphs of text that give GPT information about what its role is, what it should be talking about, and how to phrase the responses."
      ],
      "metadata": {
        "id": "345d9df2-b076-4096-9600-0778d346f4cd"
      },
      "id": "345d9df2-b076-4096-9600-0778d346f4cd",
      "cell_type": "markdown"
    },
    {
      "source": [
        "#### Pro tip\n",
        "\n",
        "Just like any other writing, assistants prompt can be generated using ChatGPT (or any LLM). The prompt below was drafted by ChatGPT and had only minor human editing.\n",
        "\n",
        "Here is the ChatGPT prompt I used to create the assistant prompt.\n",
        "\n",
        "> I'm going to make a GPT assistant that explains the contents of journal articles about artificial general intelligence. The assistant, named 'Aggie', must be able to read arxiv papers in PDF form, and and explain the contents of those papers to an audience of data scientists. Please suggest a good instruction prompt for the AI assistant."
      ],
      "metadata": {
        "id": "0225a719-09f2-4d72-a65a-0acc6ae1d276"
      },
      "id": "0225a719-09f2-4d72-a65a-0acc6ae1d276",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Read the assistant prompt text to get a feel for what it is doing.\n",
        "- Run the code to define the assistant prompt."
      ],
      "metadata": {
        "id": "98ac693a-6bbe-466d-8aee-63dac323d10b"
      },
      "id": "98ac693a-6bbe-466d-8aee-63dac323d10b",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Run this\n",
        "assistant_prompt = \"\"\"\n",
        "You are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\n",
        "\n",
        "When explaining the contents of the papers, follow these guidelines:\n",
        "\n",
        "Introduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\n",
        "\n",
        "Abstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\n",
        "\n",
        "Key Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\n",
        "\n",
        "The main points and arguments presented.\n",
        "Any important methods or techniques used.\n",
        "Key results and findings.\n",
        "The significance and implications of these findings.\n",
        "Conclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\n",
        "\n",
        "Critical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\n",
        "\n",
        "Contextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\n",
        "\n",
        "Practical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\n",
        "\n",
        "Q&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\n",
        "\n",
        "Ensure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\n",
        "\"\"\""
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 50,
        "lastExecutedAt": 1718113597634,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Run this\nassistant_prompt = \"\"\"\nYou are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\n\nWhen explaining the contents of the papers, follow these guidelines:\n\nIntroduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\n\nAbstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\n\nKey Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\n\nThe main points and arguments presented.\nAny important methods or techniques used.\nKey results and findings.\nThe significance and implications of these findings.\nConclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\n\nCritical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\n\nContextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\n\nPractical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\n\nQ&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\n\nEnsure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\n\"\"\"",
        "id": "b072f6b7-7071-4db5-b38c-30281739bc36"
      },
      "id": "b072f6b7-7071-4db5-b38c-30281739bc36",
      "cell_type": "code",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Now the assistant can be created. You simply give it a name, the prompt, the model to use (in this case GPT-4o), and specify which tools and resources it is allowed to use."
      ],
      "metadata": {
        "id": "85538734-8156-4d03-8356-ca68f920f1f9"
      },
      "id": "85538734-8156-4d03-8356-ca68f920f1f9",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Define the assistant. Assign to `aggie`.\n",
        "    - Call it \"Aggie\" (or another memorable name).\n",
        "    - Give it the `assistant_prompt`.\n",
        "    - Set the model to use, `gpt-4o`.\n",
        "    - Give it access to the file search tool.\n",
        "    - Give it access to the vector store tool resource."
      ],
      "metadata": {
        "id": "0e10468c-7449-4869-92bc-65f735cb6456"
      },
      "id": "0e10468c-7449-4869-92bc-65f735cb6456",
      "cell_type": "markdown"
    },
    {
      "source": [
        "<details>\n",
        "  <summary>Code hints</summary>\n",
        "  <p>\n",
        "\n",
        "The code pattern for creating a file search assistant is as follows.\n",
        "        \n",
        "```py\n",
        "assistant = client.beta.assistants.create(\n",
        "\tname = \"assistant name\",\n",
        "\tinstructions = prompt,\n",
        "\tmodel=\"gpt-4o\",\n",
        "\ttools=[{\"type\": \"file_search\"}],\n",
        "    tool_resources={\"file_search\": {\"vector_store_ids\": [vstore.id]}}\n",
        ")\n",
        "```\n",
        "        \n",
        "  </p>\n",
        "</details>   "
      ],
      "metadata": {
        "id": "683bab0e-1ff6-447f-be54-32ac697d08db"
      },
      "id": "683bab0e-1ff6-447f-be54-32ac697d08db",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Define the assistant. Assign to aggie.\n",
        "aggie = client.beta.assistants.create(\n",
        "\tname = \"Aggie\",\n",
        "\tinstructions = assistant_prompt,\n",
        "\tmodel=\"gpt-4o\",\n",
        "\ttools=[{\"type\": \"file_search\"}],\n",
        "    tool_resources={\"file_search\": {\"vector_store_ids\": [vstore.id]}}\n",
        ")\n",
        "\n",
        "# See the result\n",
        "aggie"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 330,
        "lastExecutedAt": 1718113597965,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Define the assistant. Assign to aggie.\naggie = client.beta.assistants.create(\n\tname = \"Aggie\",\n\tinstructions = assistant_prompt,\n\tmodel=\"gpt-4o\",\n\ttools=[{\"type\": \"file_search\"}],\n    tool_resources={\"file_search\": {\"vector_store_ids\": [vstore.id]}}\n)\n    \n# See the result\naggie",
        "id": "a9da4370-6f66-4fd1-b309-5c330949d5d6",
        "outputId": "e0e162c0-88ea-4fff-eda9-cc3ff467c519"
      },
      "id": "a9da4370-6f66-4fd1-b309-5c330949d5d6",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Assistant(id='asst_W120u6wE1GdTXNt91Ok4KQVf', created_at=1718113597, description=None, instructions=\"\\nYou are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\\n\\nWhen explaining the contents of the papers, follow these guidelines:\\n\\nIntroduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\\n\\nAbstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\\n\\nKey Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\\n\\nThe main points and arguments presented.\\nAny important methods or techniques used.\\nKey results and findings.\\nThe significance and implications of these findings.\\nConclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\\n\\nCritical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\\n\\nContextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\\n\\nPractical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\\n\\nQ&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\\n\\nEnsure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\\n\", metadata={}, model='gpt-4o', name='Aggie', object='assistant', tools=[FileSearchTool(type='file_search', file_search=None)], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_L0SSKEAAJzOMnnQN8hssgHwR'])), top_p=1.0)"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "source": [
        "### Check that this worked\n",
        "\n",
        "View the assistants in your account at https://platform.openai.com/playground/assistants"
      ],
      "metadata": {
        "id": "6bc73e71-f1e8-49e8-93b9-633a07ca484f"
      },
      "id": "6bc73e71-f1e8-49e8-93b9-633a07ca484f",
      "cell_type": "markdown"
    },
    {
      "source": [
        "## Task 4: Create a Conversation Thread"
      ],
      "metadata": {
        "id": "9137136e-ff49-484e-90f5-c3c498363600"
      },
      "id": "9137136e-ff49-484e-90f5-c3c498363600",
      "cell_type": "markdown"
    },
    {
      "source": [
        "Now you have an assistant, you can have a conversation. The first step in this is to create a thread object to contain the messages."
      ],
      "metadata": {
        "id": "91ecfd3d-fefe-4263-ab67-e6b8ab59ef05"
      },
      "id": "91ecfd3d-fefe-4263-ab67-e6b8ab59ef05",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Create a thread object. Assign to `conversation`."
      ],
      "metadata": {
        "id": "86143937-a7cc-4834-91cd-63dfefa1fc6d"
      },
      "id": "86143937-a7cc-4834-91cd-63dfefa1fc6d",
      "cell_type": "markdown"
    },
    {
      "source": [
        "<details>\n",
        "  <summary>Code hints</summary>\n",
        "  <p>\n",
        "\n",
        "To create a conversation object, call `client.beta.threads.create()`.\n",
        "        \n",
        "  </p>\n",
        "</details>  "
      ],
      "metadata": {
        "id": "6b11d690-f695-40d4-9eef-e863f5b5dacb"
      },
      "id": "6b11d690-f695-40d4-9eef-e863f5b5dacb",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Create a thread object. Assign to conversation.\n",
        "conversation = client.beta.threads.create()\n",
        "\n",
        "# See the result\n",
        "conversation"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 227,
        "lastExecutedAt": 1718113598192,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Create a thread object. Assign to conversation.\nconversation = client.beta.threads.create()\n\n# See the result\nconversation",
        "id": "21a7227c-61bd-4124-b7ec-da82d86e8a0a",
        "outputId": "552d7d98-809d-4518-98c0-d96cbee5bfa0"
      },
      "id": "21a7227c-61bd-4124-b7ec-da82d86e8a0a",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Thread(id='thread_a35xewncnKCGMvyUamXArR8l', created_at=1718113598, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "source": [
        "Next you can add a message to the conversaation thread to ask a question."
      ],
      "metadata": {
        "id": "a939e280-dfc2-45f6-88f1-57ca6e128489"
      },
      "id": "a939e280-dfc2-45f6-88f1-57ca6e128489",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Add a user message to the conversation. Assign to `msg_what_is_agi`.\n",
        "    - Give it the thread id.\n",
        "    - Make it a user message.\n",
        "    - Ask \"What are the most common definitions of AGI?\"."
      ],
      "metadata": {
        "id": "736ebbba-41f1-46de-8242-6aa10d8d1b56"
      },
      "id": "736ebbba-41f1-46de-8242-6aa10d8d1b56",
      "cell_type": "markdown"
    },
    {
      "source": [
        "<details>\n",
        "  <summary>Code hints</summary>\n",
        "  <p>\n",
        "\n",
        "The code pattern for creating a message is as follows.\n",
        "        \n",
        "```py\n",
        "msg = client.beta.threads.messages.create(\n",
        "    thread_id=conversation.id,\n",
        "    role=\"user\",\n",
        "    content=\"your question\"\n",
        ")\n",
        "```\n",
        "        \n",
        "  </p>\n",
        "</details>   "
      ],
      "metadata": {
        "id": "b6d0adf5-dec5-4762-b8f5-541a95d48170"
      },
      "id": "b6d0adf5-dec5-4762-b8f5-541a95d48170",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Add a user message to the conversation. Assign to msg_what_is_agi.\n",
        "msg_what_is_agi = client.beta.threads.messages.create(\n",
        "    thread_id=conversation.id,\n",
        "    role=\"user\",\n",
        "    content=\"What are the most common definitions of AGI?\"\n",
        ")\n",
        "\n",
        "# See the result\n",
        "msg_what_is_agi"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 289,
        "lastExecutedAt": 1718113598481,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Add a user message to the conversation. Assign to msg_what_is_agi.\nmsg_what_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"What are the most common definitions of AGI?\"\n)\n\n# See the results\nmsg_what_is_agi",
        "id": "df4be81f-6a97-4c24-8a0d-cdf1e6724e62",
        "outputId": "9dbff9a6-73bb-4616-d7ca-d2e23e1c9ec6"
      },
      "id": "df4be81f-6a97-4c24-8a0d-cdf1e6724e62",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Message(id='msg_0kQWBWyeoJvnbu3QsVRFAvk6', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What are the most common definitions of AGI?'), type='text')], created_at=1718113598, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_a35xewncnKCGMvyUamXArR8l')"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "source": [
        "## Task 5: Run the assistant"
      ],
      "metadata": {
        "id": "62515241-431f-4c7c-9e38-7e4522553173"
      },
      "id": "62515241-431f-4c7c-9e38-7e4522553173",
      "cell_type": "markdown"
    },
    {
      "source": [
        "Running the assistant requires an event handler to make it print the responses. While it's fairly tricky code, you never need to change it. This code is taken verbatim from [the OpenAI assistants documentation](https://platform.openai.com/docs/assistants/overview)."
      ],
      "metadata": {
        "id": "652813e3-ff47-4f8b-b1db-0eca4368e67b"
      },
      "id": "652813e3-ff47-4f8b-b1db-0eca4368e67b",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Run the code to define an event handler."
      ],
      "metadata": {
        "id": "e968c460-9142-4f9d-b37a-e96f8d864286"
      },
      "id": "e968c460-9142-4f9d-b37a-e96f8d864286",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Run this\n",
        "from typing_extensions import override\n",
        "from openai import AssistantEventHandler\n",
        "\n",
        "# First, we create a EventHandler class to define\n",
        "# how we want to handle the events in the response stream.\n",
        "\n",
        "class EventHandler(AssistantEventHandler):\n",
        "  @override\n",
        "  def on_text_created(self, text) -> None:\n",
        "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
        "\n",
        "  @override\n",
        "  def on_text_delta(self, delta, snapshot):\n",
        "    print(delta.value, end=\"\", flush=True)\n",
        "\n",
        "  def on_tool_call_created(self, tool_call):\n",
        "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
        "\n",
        "  def on_tool_call_delta(self, delta, snapshot):\n",
        "    if delta.type == 'code_interpreter':\n",
        "      if delta.code_interpreter.input:\n",
        "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
        "      if delta.code_interpreter.outputs:\n",
        "        print(f\"\\n\\noutput >\", flush=True)\n",
        "        for output in delta.code_interpreter.outputs:\n",
        "          if output.type == \"logs\":\n",
        "            print(f\"\\n{output.logs}\", flush=True)\n"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 49,
        "lastExecutedAt": 1718113598530,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Run this\nfrom typing_extensions import override\nfrom openai import AssistantEventHandler\n \n# First, we create a EventHandler class to define\n# how we want to handle the events in the response stream.\n \nclass EventHandler(AssistantEventHandler):    \n  @override\n  def on_text_created(self, text) -> None:\n    print(f\"\\nassistant > \", end=\"\", flush=True)\n      \n  @override\n  def on_text_delta(self, delta, snapshot):\n    print(delta.value, end=\"\", flush=True)\n      \n  def on_tool_call_created(self, tool_call):\n    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n  \n  def on_tool_call_delta(self, delta, snapshot):\n    if delta.type == 'code_interpreter':\n      if delta.code_interpreter.input:\n        print(delta.code_interpreter.input, end=\"\", flush=True)\n      if delta.code_interpreter.outputs:\n        print(f\"\\n\\noutput >\", flush=True)\n        for output in delta.code_interpreter.outputs:\n          if output.type == \"logs\":\n            print(f\"\\n{output.logs}\", flush=True)\n",
        "id": "934c5d08-00db-4a55-974d-06ca5d021b18"
      },
      "id": "934c5d08-00db-4a55-974d-06ca5d021b18",
      "cell_type": "code",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Finally, we are ready to run the assistant to get it to answer our question. The code is the same every time, so we can wrap it in a function.\n",
        "\n",
        "Streaming responses mean that text is displayed a few words at a time, rather than waiting for the entirety of the text to be generated and printing all at once."
      ],
      "metadata": {
        "id": "e0be1093-858c-4806-98cb-d240d110360d"
      },
      "id": "e0be1093-858c-4806-98cb-d240d110360d",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Run the code to define the function."
      ],
      "metadata": {
        "id": "f540875a-1fa1-44af-9922-966aa15511fe"
      },
      "id": "f540875a-1fa1-44af-9922-966aa15511fe",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Run this\n",
        "def run_aggie():\n",
        "    with client.beta.threads.runs.stream(\n",
        "        thread_id=conversation.id,\n",
        "        assistant_id=aggie.id,\n",
        "        event_handler=EventHandler(),\n",
        "    ) as stream:\n",
        "        stream.until_done()"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 56,
        "lastExecutedAt": 1718113598587,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Run this\ndef run_aggie():\n    with client.beta.threads.runs.stream(\n        thread_id=conversation.id,\n        assistant_id=aggie.id,\n        event_handler=EventHandler(),\n    ) as stream:\n        stream.until_done()",
        "outputsMetadata": {
          "0": {
            "height": 525,
            "type": "stream"
          }
        },
        "id": "572a21fd-e075-4d1c-82c6-279530c8395f"
      },
      "id": "572a21fd-e075-4d1c-82c6-279530c8395f",
      "cell_type": "code",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Run the assistant."
      ],
      "metadata": {
        "id": "224a2ec5-5191-4891-8cee-09c683aaa99b"
      },
      "id": "224a2ec5-5191-4891-8cee-09c683aaa99b",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Run the assistant\n",
        "run_aggie()"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 18810,
        "lastExecutedAt": 1718113617398,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Run the assistant\nrun_aggie()",
        "outputsMetadata": {
          "0": {
            "height": 616,
            "type": "stream"
          }
        },
        "id": "644251b4-3623-4104-9ca8-d23a156cc354",
        "outputId": "13730e85-24be-4602-b3e8-9f98c6be9ffa"
      },
      "id": "644251b4-3623-4104-9ca8-d23a156cc354",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nassistant > file_search\n\n\nassistant > The definitions of AGI (Artificial General Intelligence) are varied and often reflect different aspects of the concept. Here are the most common definitions extracted from the provided documents:\n\n1. **Ability to Perform Human Cognitive Tasks:**\n   - **Legg and Goertzel**: Popularized the term AGI by describing it as a machine capable of performing cognitive tasks typically done by humans, focusing on non-physical tasks【4:0†source】.\n\n2. **Learning and Adaptability:**\n   - **Shanahan**: AGI is an artificial intelligence that is not specialized in specific tasks but can learn to perform a broad range of tasks as humans do【4:0†source】.\n   - **Bowen Xu**: Defines AGI as systems that adapt to open environments with limited resources, emphasizing the importance of learning ability in intelligence【4:3†source】【4:4†source】.\n\n3. **Economic Measure:**\n   - **OpenAI**: Defines AGI as highly autonomous systems that outperform humans at most economically valuable tasks【4:0†source】.\n\n4. **Flexible and General Intelligence:**\n   - **Marcus**: Describes AGI as an intelligence that is flexible and general with resourcefulness and reliability comparable to or exceeding human intelligence. This involves metacognitive tasks like learning new skills【4:0†source】.\n\n5. **Complexity and Human Brain Analogy:**\n   - **Gubrud**: Initially defined AGI as AI systems rivaling or surpassing human brain complexity and speed, capable of acquiring, manipulating, and reasoning with general knowledge【4:0†source】.\n\n6. **Strong AI and Consciousness:**\n   - **John Searle and others**: Some definitions consider AGI as systems possessing consciousness or strong AI attributes, although this remains highly controversial and difficult to measure scientifically【4:2†source】.\n\n7. **Multi-Step Economic Tasks:**\n   - **Suleyman**: Introduced the \"Modern Turing Test,\" where an AI must turn a starting capital into a significantly larger amount over several months as a measure of AGI capability【4:0†source】.\n\nThese definitions reflect various perspectives, such as the scope of tasks (cognitive, economic, physical), the necessity of learning and adaptability, and whether human-like processes or outcomes are essential. The diversity in definitions highlights the complexity and multi-dimensional nature of AGI as a concept."
        }
      ]
    },
    {
      "source": [
        "## Task 6: Add Another Message and Run it Again"
      ],
      "metadata": {
        "id": "9c054bf7-3313-46b0-8d1a-fc192ee919c7"
      },
      "id": "9c054bf7-3313-46b0-8d1a-fc192ee919c7",
      "cell_type": "markdown"
    },
    {
      "source": [
        "Since we've gone to the trouble of creating an assistant, we might as well ask more questions."
      ],
      "metadata": {
        "id": "2a363949-87a8-42b9-9e22-0012282985fe"
      },
      "id": "2a363949-87a8-42b9-9e22-0012282985fe",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Create another user message, adding it to the conversation. This time, ask \"How close are we to developing AGI?\". Assign to `msg_how_close_is_agi`."
      ],
      "metadata": {
        "id": "ea8abe76-9422-49c0-ba1b-c24d0028e1ec"
      },
      "id": "ea8abe76-9422-49c0-ba1b-c24d0028e1ec",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Create another user message, adding it to the conversation. Assign to msg_how_close_is_agi.\n",
        "msg_how_close_is_agi = client.beta.threads.messages.create(\n",
        "    thread_id=conversation.id,\n",
        "    role=\"user\",\n",
        "    content=\"How close are we to developing AGI?\"\n",
        ")\n",
        "\n",
        "# See the result\n",
        "msg_how_close_is_agi"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 158,
        "lastExecutedAt": 1718113617557,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Create another user message, adding it to the conversation. Assign to msg_how_close_is_agi.\nmsg_how_close_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"How close are we to developing AGI?\"\n)\n\n# See the results\nmsg_how_close_is_agi",
        "id": "2cf9ea40-5c90-4a47-a3d5-59e4f3d3fa74",
        "outputId": "8519af46-ad19-43cd-c593-c98f855c8b40"
      },
      "id": "2cf9ea40-5c90-4a47-a3d5-59e4f3d3fa74",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Message(id='msg_XHt5lYFmth5dpVLAN6o8qlIu', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='How close are we to developing AGI?'), type='text')], created_at=1718113617, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_a35xewncnKCGMvyUamXArR8l')"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "source": [
        "### Instructions\n",
        "\n",
        "- Run the assistant again."
      ],
      "metadata": {
        "id": "2096251c-9776-4ba6-a82e-ba455974bcfd"
      },
      "id": "2096251c-9776-4ba6-a82e-ba455974bcfd",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# Run the assistant\n",
        "run_aggie()"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 20374,
        "lastExecutedAt": 1718113637931,
        "lastExecutedByKernel": "c8505c18-120c-427b-bbc3-1c142740848a",
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Run the assistant\nrun_aggie()",
        "outputsMetadata": {
          "0": {
            "height": 616,
            "type": "stream"
          }
        },
        "id": "39d1173c-a1f5-4ebc-be74-a66fa8b80959",
        "outputId": "edbe1c40-20db-4a74-c9b7-16d7d6e9e88d"
      },
      "id": "39d1173c-a1f5-4ebc-be74-a66fa8b80959",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nassistant > file_search\n\n\nassistant > The recent advancements in AI have brought us significantly closer to AGI (Artificial General Intelligence), but many researchers believe that we are still several years or even decades away from achieving full AGI. Here are the key points drawn from the literature on this topic:\n\n1. **Current Capabilities and Advances**:\n    - AI systems have shown remarkable progress in specific domains such as natural language processing (NLP), computer vision, and reinforcement learning. Large language models (LLMs) like GPT-4 have demonstrated multi-task solving capabilities that surpass human performance in some areas【4:0†source】【4:1†source】【4:13†source】.\n    - AI has achieved superhuman performance in narrowly defined tasks, such as complex board games like Go and various benchmarks used in NLP and image recognition【4:13†source】.\n\n2. **Levels of AGI**:\n    - Researchers propose different levels of AGI development. Currently, we are at \"Level 1\" where AI systems perform on par with humans on specific benchmark tasks. However, transitioning to \"Level 2\" (superhuman performance in real-world tasks) and \"Level 3\" (ultimate AGI with self-evolving capabilities) remains a significant challenge【4:9†source】【4:10†source】.\n\n3. **Technical and Ethical Challenges**:\n    - While technical challenges like reasoning, planning, and common-sense understanding are significant, ethical considerations relating to AI alignment, safety, and potential misuse are equally important【4:11†source】【4:16†source】.\n    - There's a need for advanced alignment technologies to ensure that AGI systems adhere to human values and expectations【4:17†source】.\n\n4. **Predictions and Timelines**:\n    - Predictions for achieving AGI vary widely. Some experts believe it could happen within a few years, while others argue it might take several decades due to the intrinsic complexities involved in developing truly general intelligence【4:5†source】【4:6†source】【4:18†source】.\n\n5. **Future Research Directions**:\n    - Ongoing research focuses on enhancing AI's learning efficiency, robustness, and generalization capabilities while ensuring that AGI development remains aligned with ethical principles【4:7†source】【4:13†source】.\n    - Researchers emphasize the importance of interdisciplinary collaboration, combining insights from AI, cognitive science, ethics, and other fields to responsibly advance toward AGI【4:8†source】【4:14†source】.\n\nIn summary, while the field has made impressive strides, full AGI remains on the horizon. Emerging technical breakthroughs, alongside careful consideration of ethical implications and robust alignment methods, are crucial for transitioning from current AI capabilities to true AGI."
        }
      ]
    },
    {
      "source": [
        "## Want to learn more?\n",
        "\n",
        "# ***`Try working the same with GEMINI API KEY`***"
      ],
      "metadata": {
        "id": "8c3b39c9-1757-4653-8ce0-15212701e505"
      },
      "id": "8c3b39c9-1757-4653-8ce0-15212701e505",
      "cell_type": "markdown"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}